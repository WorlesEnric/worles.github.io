{
    "version": "https://jsonfeed.org/version/1",
    "title": "Qihang&apos;s site",
    "home_page_url": "http://localhost:4000/",
    "feed_url": "http://localhost:4000/feed.json",
    "description": "Here we go",
    "icon": "http://localhost:4000/apple-touch-icon.png",
    "favicon": "http://localhost:4000/favicon.ico",
    "expired": false,
    
    "author":  {
        "name": "Qihang Wang",
        "url": null,
        "avatar": null
    },
    
"items": [
    
        {
            "id": "http://localhost:4000/2024/04/15/finetunellm",
            "title": "Finetuning Your LLM - My Workflow",
            "summary": null,
            "content_text": "",
            "content_html": "",
            "url": "http://localhost:4000/2024/04/15/finetunellm",
            
            
            
            "tags": ["LLM","workflow","llama"],
            
            "date_published": "2024-04-15T00:00:00+08:00",
            "date_modified": "2024-04-15T00:00:00+08:00",
            
                "author":  {
                "name": "Qihang Wang",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2024/04/14/ubuntuinstallation",
            "title": "DL Development Environment 1 > System Installation and Configuration",
            "summary": null,
            "content_text": "Table of Contents  Table of Contents          OS Installation                   Preparing Ubuntu Image                     OS Configuration                  GPU Related Configuration                     OS Installation You need:      A laptop or PC with at least 25GB of storage space.        A flash drive (12GB or above recommended).  Preparing Ubuntu Image Download the image from here. We use the Ubuntu 22.04 LTS for this guide.Staying consistent to the official tutorial, we use balenaEtcher to create the bootable USB stick. Do the following on balenaEtcher:  Select your downloaded ISO  Choose your USB flash drive  Click FlashYou may need to modify the boot option, for this, you may hold F12 while the computer starts.  Notice: If you encounter the black screen after installed the Ubuntu via try or install ubuntu. Here is the solution:      Press e to enter the edit mode when the screen shows try or install ubuntu.    Find ...quiet splash ---, delete the --- and add the nomodeset in front of quiet splash: ...nomodeset quiet splash.    Then press enter, you should enter the installation interface after several seconds of black wait.    If you still encounter the problem after installation. Please do the same when you restart the machine. (remember to boot from your ubuntu disk insdead of the flash disk)    If you successfully login, edit /etc/default/grub with sudo, find GRUB_CMDLINE_LINUX_DEFAULT=quiet splash, change it to GRUB_CMDLINE_LINUX_DEFAULT=quiet splash nomodeset.  Setting up Ubuntu installation:  Computer name: Name-PC  Name: Name  User name: name  Password:OS ConfigurationRef: Ubuntu 22.04 for DLYou may update Ubuntu before further operations:$ sudo apt update$ sudo apt full-upgrade --yes$ sudo apt autoremove --yes$ sudo apt autoclean --yes$ rebootYou can create a full-update script ~/full-update.sh to pack these operations:#!/usr/bin/env bashif [ \"$EUID\" -ne 0 ]  then echo \"Error: Please run as root.\"  exitficlearecho \"################################################################################\"echo \"Updating list of available packages...\"echo \"--------------------------------------------------------------------------------\"apt updateecho \"################################################################################\"echoecho \"################################################################################\"echo \"Upgrading the system by removing/installing/upgrading packages...\"echo \"--------------------------------------------------------------------------------\"apt full-upgrade --yesecho \"################################################################################\"echoecho \"################################################################################\"echo \"Removing automatically all unused packages...\"echo \"--------------------------------------------------------------------------------\"apt autoremove --yesecho \"################################################################################\"echoecho \"################################################################################\"echo \"Clearing out the local repository of retrieved package files...\"echo \"--------------------------------------------------------------------------------\"apt autoclean --yesecho \"################################################################################\"echoInstall the Chrome web browser by (get the deb file here):$ sudo dpkg -i google-chrome-stable_current_amd64.debInstall the developement tools by:$ sudo apt install build-essential pkg-config cmake cmake-qt-gui ninja-build valgrindInstall Python3 and venv by:$ sudo apt install python3 python3-wheel python3-pip python3-venv python3-dev python3-setuptoolsInstall Git by:$ sudo apt install git$ git config --global user.name \"Name\"$ git config --global user.email \"name@domain.com\"$ git config --global core.editor \"gedit -s\"GPU Related Configuration Now it comes to the steps for setting up NVIDIA toolkits. The process here may not align with your situation, check the NVIDIA official toturial whenever there are mistakes.Check the display hardware by:$ sudo lshw -C displayCheck CUDA and NVIDIA Driver Compatibilities here.Check TensorFlow and CUDA Compatibilities here and here.Check Torch and CUDA Campatibilities here.Here we use CUDA 11.8, install the NVIDIA Driver by:$ sudo apt install nvidia-driver-535Install the prerequisites:$ sudo apt install linux-headers-$(uname -r)Download CUDA 11.8 via:$ wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.runInstall CUDA 11.8 by (select without driver):$ sudo ./cuda_11.8.0_520.61.05_linux.run --overrideSetting up the environment variables:export PATH=$PATH:/usr/local/cuda-11.8/binexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/extras/CUPTI/lib64Test by:$ nvidia-smi$ NVCC -vInstall cuDNN v8.6 for CUDA 11.8. Login and download the deb file hereThen install by:$ sudo dpkg -i cudnn-local-repo-ubuntu2204-8.6.0.163_1.0-1_amd64.deb$ sudo cp /var/cudnn-local-repo-ubuntu2204-8.6.0.163/cudnn-local-FAED14DD-keyring.gpg /usr/share/keyrings/$ sudo apt update$ sudo apt install libcudnn8$ sudo apt install libcudnn8-dev$ sudo apt install libcudnn8-samplesThen reboot by sudo reboot",
            "content_html": "<h1 id=\"table-of-contents\">Table of Contents</h1><ul>  <li><a href=\"#table-of-contents\">Table of Contents</a>    <ul>      <li><a href=\"#os-installation-\">OS Installation </a>        <ul>          <li><a href=\"#preparing-ubuntu-image-\">Preparing Ubuntu Image </a></li>        </ul>      </li>      <li><a href=\"#os-configuration\">OS Configuration</a>        <ul>          <li><a href=\"#gpu-related-configuration-\">GPU Related Configuration </a></li>        </ul>      </li>    </ul>  </li></ul><h2 id=\"os-installation-\">OS Installation <a name=\"osinstallation\"></a></h2><p>You need:</p><ul>  <li>    <p>A laptop or PC with at least 25GB of storage space.</p>  </li>  <li>    <p>A flash drive (12GB or above recommended).</p>  </li></ul><h3 id=\"preparing-ubuntu-image-\">Preparing Ubuntu Image <a name=\"preparation\"></a></h3><p>Download the image from <a href=\"https://ubuntu.com/download/desktop\">here</a>. We use the Ubuntu 22.04 LTS for this guide.</p><p>Staying consistent to the official tutorial, we use <a href=\"https://etcher.balena.io/\">balenaEtcher</a> to create the bootable USB stick. Do the following on balenaEtcher:</p><ul>  <li>Select your downloaded ISO</li>  <li>Choose your USB flash drive</li>  <li>Click Flash</li></ul><p>You may need to modify the boot option, for this, you may hold <code>F12</code> while the computer starts.</p><blockquote>  <p>Notice: If you encounter the black screen after installed the Ubuntu via <code>try or install ubuntu</code>. Here is the solution:</p>  <ul>    <li>Press <code>e</code> to enter the edit mode when the screen shows <code>try or install ubuntu</code>.</li>    <li>Find <code>...quiet splash ---</code>, delete the <code>---</code> and add the <code>nomodeset</code> in front of <code>quiet splash</code>: <code>...nomodeset quiet splash</code>.</li>    <li>Then press <code>enter</code>, you should enter the installation interface after several seconds of black wait.</li>    <li>If you still encounter the problem after installation. Please do the same when you restart the machine. (remember to boot from your ubuntu disk insdead of the flash disk)</li>    <li>If you successfully login, edit <code>/etc/default/grub</code> with <code>sudo</code>, find <code>GRUB_CMDLINE_LINUX_DEFAULT=</code>quiet splash<code>, change it to </code>GRUB_CMDLINE_LINUX_DEFAULT=<code>quiet splash nomodeset</code>.</li>  </ul></blockquote><p>Setting up Ubuntu installation:</p><ul>  <li>Computer name: Name-PC</li>  <li>Name: Name</li>  <li>User name: name</li>  <li>Password:</li></ul><h2 id=\"os-configuration\">OS Configuration</h2><p>Ref: <a href=\"https://gist.github.com/amir-saniyan/b3d8e06145a8569c0d0e030af6d60bea\">Ubuntu 22.04 for DL</a></p><p>You may update Ubuntu before further operations:</p><pre><code class=\"language-shell\">$ sudo apt update$ sudo apt full-upgrade --yes$ sudo apt autoremove --yes$ sudo apt autoclean --yes$ reboot</code></pre><p>You can create a full-update script <code>~/full-update.sh</code> to pack these operations:</p><pre><code class=\"language-shell\">#!/usr/bin/env bashif [ \"$EUID\" -ne 0 ]  then echo \"Error: Please run as root.\"  exitficlearecho \"################################################################################\"echo \"Updating list of available packages...\"echo \"--------------------------------------------------------------------------------\"apt updateecho \"################################################################################\"echoecho \"################################################################################\"echo \"Upgrading the system by removing/installing/upgrading packages...\"echo \"--------------------------------------------------------------------------------\"apt full-upgrade --yesecho \"################################################################################\"echoecho \"################################################################################\"echo \"Removing automatically all unused packages...\"echo \"--------------------------------------------------------------------------------\"apt autoremove --yesecho \"################################################################################\"echoecho \"################################################################################\"echo \"Clearing out the local repository of retrieved package files...\"echo \"--------------------------------------------------------------------------------\"apt autoclean --yesecho \"################################################################################\"echo</code></pre><p>Install the Chrome web browser by (get the deb file <a href=\"https://www.google.com/chrome/\">here</a>):</p><pre><code class=\"language-shell\">$ sudo dpkg -i google-chrome-stable_current_amd64.deb</code></pre><p>Install the developement tools by:</p><pre><code class=\"language-shell\">$ sudo apt install build-essential pkg-config cmake cmake-qt-gui ninja-build valgrind</code></pre><p>Install Python3 and venv by:</p><pre><code class=\"language-shell\">$ sudo apt install python3 python3-wheel python3-pip python3-venv python3-dev python3-setuptools</code></pre><p>Install Git by:</p><pre><code class=\"language-shell\">$ sudo apt install git$ git config --global user.name \"Name\"$ git config --global user.email \"name@domain.com\"$ git config --global core.editor \"gedit -s\"</code></pre><h3 id=\"gpu-related-configuration-\">GPU Related Configuration <a name=\"GPU\"></a></h3><p>Now it comes to the steps for setting up NVIDIA toolkits. The process here may not align with your situation, check the NVIDIA official toturial whenever there are mistakes.</p><p>Check the display hardware by:</p><pre><code class=\"language-shell\">$ sudo lshw -C display</code></pre><p><strong>Check CUDA and NVIDIA Driver Compatibilities</strong> <a href=\"https://docs.nvidia.com/deeplearning/cudnn/reference/support-matrix.html\">here</a>.</p><p><strong>Check TensorFlow and CUDA Compatibilities</strong> <a href=\"https://www.tensorflow.org/install/gpu\">here</a> and <a href=\"https://www.tensorflow.org/install/source#gpu\">here</a>.</p><p><strong>Check Torch and CUDA Campatibilities</strong> <a href=\"https://github.com/pytorch/pytorch/blob/main/RELEASE.md#release-compatibility-matrix\">here</a>.</p><p>Here we use CUDA 11.8, install the NVIDIA Driver by:</p><pre><code class=\"language-shell\">$ sudo apt install nvidia-driver-535</code></pre><p>Install the prerequisites:</p><pre><code class=\"language-shell\">$ sudo apt install linux-headers-$(uname -r)</code></pre><p>Download CUDA 11.8 via:</p><pre><code class=\"language-shell\">$ wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run</code></pre><p>Install CUDA 11.8 by (select without driver):</p><pre><code class=\"language-shell\">$ sudo ./cuda_11.8.0_520.61.05_linux.run --override</code></pre><p>Setting up the environment variables:</p><pre><code class=\"language-shell\">export PATH=$PATH:/usr/local/cuda-11.8/binexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/extras/CUPTI/lib64</code></pre><p>Test by:</p><pre><code class=\"language-shell\">$ nvidia-smi$ NVCC -v</code></pre><p>Install cuDNN v8.6 for CUDA 11.8. Login and download the deb file <a href=\"https://developer.nvidia.com/compute/cudnn/secure/8.6.0/local_installers/11.8/cudnn-local-repo-ubuntu2204-8.6.0.163_1.0-1_amd64.deb\">here</a></p><p>Then install by:</p><pre><code class=\"language-shell\">$ sudo dpkg -i cudnn-local-repo-ubuntu2204-8.6.0.163_1.0-1_amd64.deb$ sudo cp /var/cudnn-local-repo-ubuntu2204-8.6.0.163/cudnn-local-FAED14DD-keyring.gpg /usr/share/keyrings/$ sudo apt update$ sudo apt install libcudnn8$ sudo apt install libcudnn8-dev$ sudo apt install libcudnn8-samples</code></pre><p>Then reboot by <code>sudo reboot</code></p>",
            "url": "http://localhost:4000/2024/04/14/ubuntuinstallation",
            
            
            
            "tags": ["linux","installation"],
            
            "date_published": "2024-04-14T00:00:00+08:00",
            "date_modified": "2024-04-14T00:00:00+08:00",
            
                "author":  {
                "name": "Qihang Wang",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2024/04/14/softwares",
            "title": "DL Development Environment 2 > Tools You May Need",
            "summary": null,
            "content_text": "Table of Contents  Table of Contents          Source Mirrors                   Ubuntu Sources (22.04 LTS jammy)          PyPI          Docker CE          Dockerhub Mirror                    Proxy       Visual Studio Code       Source Mirrors For users who experience the low connection qualities on certain software sources, you may consider using the source mirrors. Here we record the operations using Tsinghua Open Source Mirror (TUNA).Ubuntu Sources (22.04 LTS jammy)Replace the content of /etc/apt/sources.list with:deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiversedeb http://security.ubuntu.com/ubuntu/ jammy-security main restricted universe multiverse# deb-src http://security.ubuntu.com/ubuntu/ jammy-security main restricted universe multiverse# deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse# # deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiversePyPIFor the temporary usage, you may directly use:pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-packageSet as default, you may use:python -m pip install --upgrade pip# use the below if you cannot upgrade# python -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade pippip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simpleDocker CEYou can automatically install docker via:export DOWNLOAD_URL=\"http://mirrors.tuna.tsinghua.edu.cn/docker-ce\"# For curlcurl -fsSL https://get.docker.com/ | sh# for wgetwget -O- https://get.docker.com/ | shOR, you can install mannually. The following commands are for Ubuntu, you can change them according to the instructions here. Uninstall the old version (if there is):for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do apt-get remove $pkg; doneThen install the dependencies:apt-get updateapt-get install ca-certificates curl gnupgAdd the repo:install -m 0755 -d /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpgsudo chmod a+r /etc/apt/keyrings/docker.gpgecho \\  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] http://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \\  \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\  tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullInstall the docker:apt-get updateapt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginDockerhub MirrorYou can use Aliyun container mirror service to accelerate the docker pull xxx from docker hub.Proxy For the similar reasons, you may want to equip your environment with a proxy. This blog shows the utilization of clash for linux for this purpose. You may find other solutions via google.Download the clash via:$ git clone https://github.com/wanhebin/clash-for-linux.gitEnter the directory cd clash-for-linux and edit CLASH_URL by vim .env.Start the service via:$ sudo bash start.sh# In a new terminal$ source /etc/profile.d/clash.sh$ proxy_onYou may check if the service is correctly started:$ netstat -tln | grep -E '9090|789.'tcp        0      0 127.0.0.1:9090          0.0.0.0:*               LISTEN     tcp6       0      0 :::7890                 :::*                    LISTEN     tcp6       0      0 :::7891                 :::*                    LISTEN     tcp6       0      0 :::7892                 :::*   $ env | grep -E 'http_proxy|https_proxy'http_proxy=http://127.0.0.1:7890https_proxy=http://127.0.0.1:7890                 If you wang to shutdown or restart (maybe for updating configurations):#shuting downsudo bash shutdown.shproxy_off#restartingsudo bash restart.shclash dashboard is by default hosted on http://192.168.0.1:9090/.Visual Studio Code Download the VSCode client here, then install via sudo apt install ./&lt;file&gt;.deb.",
            "content_html": "<h1 id=\"table-of-contents\">Table of Contents</h1><ul>  <li><a href=\"#table-of-contents\">Table of Contents</a>    <ul>      <li><a href=\"#source-mirrors-\">Source Mirrors </a>        <ul>          <li><a href=\"#ubuntu-sources-2204-lts-jammy\">Ubuntu Sources (22.04 LTS jammy)</a></li>          <li><a href=\"#pypi\">PyPI</a></li>          <li><a href=\"#docker-ce\">Docker CE</a></li>          <li><a href=\"#dockerhub-mirror\">Dockerhub Mirror</a></li>        </ul>      </li>      <li><a href=\"#proxy-\">Proxy </a></li>      <li><a href=\"#visual-studio-code-\">Visual Studio Code </a></li>    </ul>  </li></ul><h2 id=\"source-mirrors-\">Source Mirrors <a name=\"mirror\"></a></h2><p>For users who experience the low connection qualities on certain software sources, you may consider using the source mirrors. Here we record the operations using Tsinghua Open Source Mirror (TUNA).</p><h3 id=\"ubuntu-sources-2204-lts-jammy\">Ubuntu Sources (22.04 LTS jammy)</h3><p>Replace the content of <code>/etc/apt/sources.list</code> with:</p><pre><code class=\"language-shell\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiversedeb http://security.ubuntu.com/ubuntu/ jammy-security main restricted universe multiverse# deb-src http://security.ubuntu.com/ubuntu/ jammy-security main restricted universe multiverse# deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse# # deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse</code></pre><h3 id=\"pypi\">PyPI</h3><p>For the temporary usage, you may directly use:<code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package</code></p><p>Set as default, you may use:</p><pre><code class=\"language-shell\">python -m pip install --upgrade pip# use the below if you cannot upgrade# python -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade pippip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</code></pre><h3 id=\"docker-ce\">Docker CE</h3><p>You can automatically install docker via:</p><pre><code class=\"language-shell\">export DOWNLOAD_URL=\"http://mirrors.tuna.tsinghua.edu.cn/docker-ce\"# For curlcurl -fsSL https://get.docker.com/ | sh# for wgetwget -O- https://get.docker.com/ | sh</code></pre><p>OR, you can install mannually. The following commands are for Ubuntu, you can change them according to the instructions <a href=\"https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/\">here</a>. Uninstall the old version (if there is):</p><pre><code class=\"language-shell\">for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do apt-get remove $pkg; done</code></pre><p>Then install the dependencies:</p><pre><code class=\"language-shell\">apt-get updateapt-get install ca-certificates curl gnupg</code></pre><p>Add the repo:</p><pre><code class=\"language-shell\">install -m 0755 -d /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpgsudo chmod a+r /etc/apt/keyrings/docker.gpgecho \\  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] http://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \\  \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\  tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</code></pre><p>Install the docker:</p><pre><code class=\"language-shell\">apt-get updateapt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</code></pre><h3 id=\"dockerhub-mirror\">Dockerhub Mirror</h3><p>You can use Aliyun container mirror service to accelerate the <code>docker pull xxx</code> from docker hub.</p><h2 id=\"proxy-\">Proxy <a name=\"proxy\"></a></h2><p>For the similar reasons, you may want to equip your environment with a proxy. This blog shows the utilization of <a href=\"https://github.com/wnlen/clash-for-linux\">clash for linux</a> for this purpose. You may find other solutions via google.</p><p>Download the clash via:</p><pre><code class=\"language-shell\">$ git clone https://github.com/wanhebin/clash-for-linux.git</code></pre><p>Enter the directory <code>cd clash-for-linux</code> and edit <code>CLASH_URL</code> by <code>vim .env</code>.</p><p>Start the service via:</p><pre><code class=\"language-shell\">$ sudo bash start.sh# In a new terminal$ source /etc/profile.d/clash.sh$ proxy_on</code></pre><p>You may check if the service is correctly started:</p><pre><code class=\"language-shell\">$ netstat -tln | grep -E '9090|789.'tcp        0      0 127.0.0.1:9090          0.0.0.0:*               LISTEN     tcp6       0      0 :::7890                 :::*                    LISTEN     tcp6       0      0 :::7891                 :::*                    LISTEN     tcp6       0      0 :::7892                 :::*   $ env | grep -E 'http_proxy|https_proxy'http_proxy=http://127.0.0.1:7890https_proxy=http://127.0.0.1:7890                 </code></pre><p>If you wang to shutdown or restart (maybe for updating configurations):</p><pre><code class=\"language-shell\">#shuting downsudo bash shutdown.shproxy_off#restartingsudo bash restart.sh</code></pre><p>clash dashboard is by default hosted on <code>http://192.168.0.1:9090/</code>.</p><h2 id=\"visual-studio-code-\">Visual Studio Code <a name=\"vscode\"></a></h2><p>Download the VSCode client <a href=\"https://code.visualstudio.com/\">here</a>, then install via <code>sudo apt install ./&lt;file&gt;.deb</code>.</p>",
            "url": "http://localhost:4000/2024/04/14/softwares",
            
            
            
            "tags": ["linux","installation"],
            
            "date_published": "2024-04-14T00:00:00+08:00",
            "date_modified": "2024-04-14T00:00:00+08:00",
            
                "author":  {
                "name": "Qihang Wang",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2024/04/14/dllibs",
            "title": "DL Development Environment 3 > Libararies You May Need",
            "summary": null,
            "content_text": "Table of Contents  Table of Contents          ML libararies       Pytorch       Tensorflow        ML libararies Prepare the common ML libs (you can also access them via anaconda)$ python3 -m venv ~/venvs/ml$ source ~/venvs/ml/bin/activate(ml) $ pip install --upgrade pip setuptools wheel(ml) $ pip install --upgrade numpy scipy matplotlib ipython jupyter pandas sympy nose(ml) $ pip install --upgrade scikit-learn scikit-image(ml) $ deactivatePytorch Pytorch CPU:$ python3 -m venv ~/venvs/torchcpu$ source ~/venvs/torchcpu/bin/activate(torchcpu) $ pip install --upgrade pip setuptools wheel(torchcpu) $ pip install --upgrade opencv-python opencv-contrib-python(torchcpu) $ pip install --upgrade torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu(torchcpu) $ deactivatePytorch GPU (ALERT: Check the CUDA and cuDNN and NVIDIA drive version Compatibilities here, and use the correct downloading name to repalce the ones below):$ python3 -m venv ~/venvs/torchgpu$ source ~/venvs/torchgpu/bin/activate(torchgpu) $ pip install --upgrade pip setuptools wheel(torchgpu) $ pip install --upgrade opencv-python opencv-contrib-python(torchgpu) $ pip install --upgrade torch torchvision torchaudio(torchgpu) $ deactivateAfter installation, you may check the availability:$ source ~/venvs/torchgpu/bin/activate(torchgpu) $ python&gt;&gt;&gt; import torch&gt;&gt;&gt; torch.cuda.is_available()&gt;&gt;&gt; exit()(torchgpu) $ deactivateTensorflow  Tensorflow CPU:$ python3 -m venv ~/venvs/tfcpu$ source ~/venvs/tfcpu/bin/activate(tfcpu) $ pip install --upgrade pip setuptools wheel(tfcpu) $ pip install --upgrade opencv-python opencv-contrib-python(tfcpu) $ pip install --upgrade tensorflow-cpu tensorboard keras(tfcpu) $ deactivateTensorflow GPU (similar to Pytorch, check the official tutorial)$ python3 -m venv ~/venvs/tfgpu$ source ~/venvs/tfgpu/bin/activate(tfgpu) $ pip install --upgrade pip setuptools wheel(tfgpu) $ pip install --upgrade opencv-python opencv-contrib-python(tfgpu) $ pip install --upgrade tensorflow tensorboard keras(tfgpu) $ deactivate",
            "content_html": "<h1 id=\"table-of-contents\">Table of Contents</h1><ul>  <li><a href=\"#table-of-contents\">Table of Contents</a>    <ul>      <li><a href=\"#ml-libararies-\">ML libararies </a></li>      <li><a href=\"#pytorch-\">Pytorch </a></li>      <li><a href=\"#tensorflow--\">Tensorflow  </a></li>    </ul>  </li></ul><h2 id=\"ml-libararies-\">ML libararies <a name=\"mllibs\"></a></h2><p>Prepare the common ML libs (you can also access them via anaconda)</p><pre><code class=\"language-shell\">$ python3 -m venv ~/venvs/ml$ source ~/venvs/ml/bin/activate(ml) $ pip install --upgrade pip setuptools wheel(ml) $ pip install --upgrade numpy scipy matplotlib ipython jupyter pandas sympy nose(ml) $ pip install --upgrade scikit-learn scikit-image(ml) $ deactivate</code></pre><h2 id=\"pytorch-\">Pytorch <a name=\"pytorch\"></a></h2><p>Pytorch CPU:</p><pre><code class=\"language-shell\">$ python3 -m venv ~/venvs/torchcpu$ source ~/venvs/torchcpu/bin/activate(torchcpu) $ pip install --upgrade pip setuptools wheel(torchcpu) $ pip install --upgrade opencv-python opencv-contrib-python(torchcpu) $ pip install --upgrade torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu(torchcpu) $ deactivate</code></pre><p>Pytorch GPU (<strong>ALERT</strong>: Check the CUDA and cuDNN and NVIDIA drive version Compatibilities <a href=\"https://github.com/pytorch/pytorch/blob/main/RELEASE.md#release-compatibility-matrix\">here</a>, and use the correct downloading name to repalce the ones below):</p><pre><code class=\"language-shell\">$ python3 -m venv ~/venvs/torchgpu$ source ~/venvs/torchgpu/bin/activate(torchgpu) $ pip install --upgrade pip setuptools wheel(torchgpu) $ pip install --upgrade opencv-python opencv-contrib-python(torchgpu) $ pip install --upgrade torch torchvision torchaudio(torchgpu) $ deactivate</code></pre><p>After installation, you may check the availability:</p><pre><code class=\"language-shell\">$ source ~/venvs/torchgpu/bin/activate(torchgpu) $ python&gt;&gt;&gt; import torch&gt;&gt;&gt; torch.cuda.is_available()&gt;&gt;&gt; exit()(torchgpu) $ deactivate</code></pre><h2 id=\"tensorflow--\">Tensorflow  <a name=\"pytorch\"></a></h2><p>Tensorflow CPU:</p><pre><code class=\"language-shell\">$ python3 -m venv ~/venvs/tfcpu$ source ~/venvs/tfcpu/bin/activate(tfcpu) $ pip install --upgrade pip setuptools wheel(tfcpu) $ pip install --upgrade opencv-python opencv-contrib-python(tfcpu) $ pip install --upgrade tensorflow-cpu tensorboard keras(tfcpu) $ deactivate</code></pre><p>Tensorflow GPU (similar to Pytorch, check the official <a href=\"https://www.tensorflow.org/install/gpu\">tutorial</a>)</p><pre><code class=\"language-shell\">$ python3 -m venv ~/venvs/tfgpu$ source ~/venvs/tfgpu/bin/activate(tfgpu) $ pip install --upgrade pip setuptools wheel(tfgpu) $ pip install --upgrade opencv-python opencv-contrib-python(tfgpu) $ pip install --upgrade tensorflow tensorboard keras(tfgpu) $ deactivate</code></pre>",
            "url": "http://localhost:4000/2024/04/14/dllibs",
            
            
            
            "tags": ["linux","installation"],
            
            "date_published": "2024-04-14T00:00:00+08:00",
            "date_modified": "2024-04-14T00:00:00+08:00",
            
                "author":  {
                "name": "Qihang Wang",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2024/04/13/introllm",
            "title": "Large Language Models - Aspects and Methods",
            "summary": null,
            "content_text": "This post is the note for reviewing the development of the Large Language Models (LLMs), for more detailed and rigorous text, please refer to the monographs.Warning: This post should not serve as an introduction text to whom may not be familiar with the deep learning methodologies, since it contains intensive personal opinions, not assured to be correct.Table of Contents  Table of Contents          Sequence-to-sequence Learning                  Recurrent Neural Network and Long Short Term Memory Network                    Sequence-to-sequence LearningDespite the purpose of giving an introduction of neural language processing, we will start from reviewing  the machine translation (MT) task, for the simplicity  of the ideas – transfrom one sequence of words to another sequence of words (in some other language).  Note that in the original paper written by Ilya et al., the sequence to sequence learning could be a quite generalizable concept, below are several examples of sequences:\"Examples of sequences\" by seq2seq ICML 17' tutorialIn my opinion, the motivation for developing the modern sequence to sequence learning methods is driven by the following two problems:      The traditional ML methods rely on the consistent input dimensions. That is to say, the model only deals with the inputs that share a constant shape.        Given the training pairs (each pair contains two sequences usually sampled from two domains), the task is essentially to match the distribution of the former to the latter. How do we model, evaluate or optimize the process?  The first problem drives the development of recurrent neural network (RNN), while the second problem drives the architecture design of the moderm seq2seq learning models. We now briefly introduce the three important models to support the further discussion, they are RNN, LSTM, and self-attention.Recurrent Neural Network and Long Short Term Memory NetworkWe would give a short introduction of the model structures and optimization techniques, the main focus of this section remains to be the discussion in the context of sequence-to-sequence learning.In short, Recurrent Neural Network (RNN) is a kind of NN architectures in which the model computation graph is directed cyclic graph, while the Long Short Term Memory (LSTM) Network is a more complex version of the core network of RNN. Though sound intuitive, RNNs are proven to be powerful in many ways, e.g., RNNs are Turing Complete, RNNs are nearly intelligence-equivalent by approaching the asymptotic limit in text compression. To make the following introduction non-trivial, we consider the predicting-next-character task, where the model is provided a sequence of characters and is required to predict the next character in the end of the sequence. (Note: The discussion here are mainly derived from the Ph.D thesis of Ilya Sutskever).RNN Formulation:There are two perspectives on RNN, view it as a single network whose computation graph is cyclic, or view it as a super deep neural network with shared weights among the blocks (unrolled view).\"An unrolled RNN\" by colah's blogMy apology for the inconsistency, but we are going to use a slightly different notation from the figure. Let $i_t$ be the input at t-th moment, and $o_t$ be the output at t-th moment. Aparently RNN utilizes a hidden representation of the data, denoted by $h_t$. Now we define the input-output map as:\\[o_t = g(h^o_t) \\\\h^o_t = W_{oh}h_t + b_o \\\\h_t = f(h^i_t) \\\\h^i_t = W_{hi}i_t + W_{hh}h_{t-1} + b_h\\]If you are familiar with the feed forward network, these are just two dense layers connected by the corresponding activation functions. The only difference is that the input layer takes the last moment’s state as part of the input, i.e., a combination of the input and the hidden state.Before we discuss the LSTM network, we take a glance at the ackpropagation through time algorithm (BPTT). We first define the training loss function of RNN as the cumulative loss over time:\\[\\mathcal{L}(o, y) = \\sum_{t=1}^T \\mathcal{l}_t(o_t, y_t)\\]Let’s calculate the partial derivative of the loss over $W_{hi}$ and $W_{hh}$, since the calculation w.r.t $W_{oh}$ is straight forward. We have the following:\\[\\frac{\\partial \\mathcal{L}}{\\partial W_{hh}} = \\sum_{t=1}^T \\frac{\\partial \\mathcal{l}_t}{\\partial W_{hh}} =  \\sum_{t=1}^T \\frac{\\partial \\mathcal{l}_t}{\\partial o_t}\\frac{\\partial o_t}{\\partial h^o_t}W_{oh}\\frac{\\partial h_t}{\\partial h^i_t}\\frac{\\partial h^i_t}{\\partial W_{hh}} \\\\\\frac{\\partial \\mathcal{L}}{\\partial W_{hi}} = \\sum_{t=1}^T \\frac{\\partial \\mathcal{l}_t}{\\partial W_{hi}} =  \\sum_{t=1}^T \\frac{\\partial \\mathcal{l}_t}{\\partial o_t}\\frac{\\partial o_t}{\\partial h^o_t}W_{oh}\\frac{\\partial h_t}{\\partial h^i_t}\\frac{\\partial h^i_t}{\\partial W_{hi}}\\]Note here you cannot directly calculate that $\\frac{\\partial h^i_t}{\\partial W_{hh}}=h_{t-1}$ since $h_{t-1} = h_{t-1}(\\cdot, W_{hh})$, that’s because $W_{hh}$ is shared across the whole sequence. Instead, we view the $h_t(W_{hh})$ as the composition of functions $h_t(h_{t-1}(W_{hh}), h_{t-2}(W_{hh}), … h_{1}(W_{hh}))$, applying the chain rule on the partial derivative, we have:\\[\\frac{\\partial h_t}{\\partial W_{hh}}=\\sum_{k=1}^t \\frac{\\partial h_{t}}{\\partial h_{k}}\\frac{\\partial h_k}{W_{hh}}\\]",
            "content_html": "<p>This post is the note for reviewing the development of the Large Language Models (LLMs), for more detailed and rigorous text, please refer to the monographs.</p><p><strong>Warning:</strong> This post should not serve as an introduction text to whom may not be familiar with the deep learning methodologies, since it contains intensive personal opinions, not assured to be correct.</p><h1 id=\"table-of-contents\">Table of Contents</h1><ul>  <li><a href=\"#table-of-contents\">Table of Contents</a>    <ul>      <li><a href=\"#sequence-to-sequence-learning\">Sequence-to-sequence Learning</a>        <ul>          <li><a href=\"#recurrent-neural-network-and-long-short-term-memory-network\">Recurrent Neural Network and Long Short Term Memory Network</a></li>        </ul>      </li>    </ul>  </li></ul><h2 id=\"sequence-to-sequence-learning\">Sequence-to-sequence Learning</h2><p>Despite the purpose of giving an introduction of neural language processing, we will start from reviewing  the machine translation (MT) task, for the simplicity  of the ideas – transfrom one sequence of words to another sequence of words (in some other language).  Note that in the original <a href=\"https://arxiv.org/pdf/1409.3215.pdf\">paper</a> written by Ilya et al., the sequence to sequence learning could be a quite generalizable concept, below are several examples of sequences:</p><p><img style=\"display: block;\" class=\"img-fluid\" src=\"https://i.imgur.com/ZVfrUta.png\" alt=\"seq2seq.\" /></p><p class=\"small\">\"Examples of sequences\" by seq2seq ICML 17' tutorial</p><p>In my opinion, the motivation for developing the modern sequence to sequence learning methods is driven by the following two problems:</p><ul>  <li>    <p>The traditional ML methods rely on the consistent input dimensions. That is to say, the model only deals with the inputs that share a constant shape.</p>  </li>  <li>    <p>Given the training pairs (each pair contains two sequences usually sampled from two domains), the task is essentially to match the distribution of the former to the latter. How do we model, evaluate or optimize the process?</p>  </li></ul><p>The first problem drives the development of recurrent neural network (RNN), while the second problem drives the architecture design of the moderm seq2seq learning models. We now briefly introduce the three important models to support the further discussion, they are RNN, LSTM, and self-attention.</p><h3 id=\"recurrent-neural-network-and-long-short-term-memory-network\">Recurrent Neural Network and Long Short Term Memory Network</h3><p>We would give a short introduction of the model structures and optimization techniques, the main focus of this section remains to be the discussion in the context of sequence-to-sequence learning.</p><p>In short, Recurrent Neural Network (RNN) is a kind of NN architectures in which the model computation graph is directed cyclic graph, while the Long Short Term Memory (LSTM) Network is a more complex version of the core network of RNN. Though sound intuitive, RNNs are proven to be powerful in many ways, e.g., <a href=\"https://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf\">RNNs are Turing Complete</a>, <a href=\"http://www.vetta.org/documents/Machine_Super_Intelligence.pdf\">RNNs are nearly intelligence-equivalent by approaching the asymptotic limit in text compression</a>. To make the following introduction non-trivial, we consider the predicting-next-character task, where the model is provided a sequence of characters and is required to predict the next character in the end of the sequence. (Note: The discussion here are mainly derived from the Ph.D <a href=\"http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf\">thesis</a> of Ilya Sutskever).</p><p><strong>RNN Formulation</strong>:</p><p>There are two perspectives on RNN, view it as a single network whose computation graph is cyclic, or view it as a super deep neural network with shared weights among the blocks (unrolled view).</p><p><img style=\"display: block;\" class=\"img-fluid\" src=\"https://i.imgur.com/ELw9Iu9.png\" alt=\"RNN.\" /></p><p class=\"small\">\"An unrolled RNN\" by colah's blog</p><p>My apology for the inconsistency, but we are going to use a slightly different notation from the figure. Let $i_t$ be the input at t-th moment, and $o_t$ be the output at t-th moment. Aparently RNN utilizes a hidden representation of the data, denoted by $h_t$. Now we define the input-output map as:</p>\\[o_t = g(h^o_t) \\\\h^o_t = W_{oh}h_t + b_o \\\\h_t = f(h^i_t) \\\\h^i_t = W_{hi}i_t + W_{hh}h_{t-1} + b_h\\]<p>If you are familiar with the feed forward network, these are just two dense layers connected by the corresponding activation functions. The only difference is that the input layer takes the last moment’s state as part of the input, i.e., a combination of the input and the hidden state.</p><p>Before we discuss the LSTM network, we take a glance at the ackpropagation through time algorithm (BPTT). We first define the training loss function of RNN as the cumulative loss over time:</p>\\[\\mathcal{L}(o, y) = \\sum_{t=1}^T \\mathcal{l}_t(o_t, y_t)\\]<p>Let’s calculate the partial derivative of the loss over $W_{hi}$ and $W_{hh}$, since the calculation w.r.t $W_{oh}$ is straight forward. We have the following:</p>\\[\\frac{\\partial \\mathcal{L}}{\\partial W_{hh}} = \\sum_{t=1}^T \\frac{\\partial \\mathcal{l}_t}{\\partial W_{hh}} =  \\sum_{t=1}^T \\frac{\\partial \\mathcal{l}_t}{\\partial o_t}\\frac{\\partial o_t}{\\partial h^o_t}W_{oh}\\frac{\\partial h_t}{\\partial h^i_t}\\frac{\\partial h^i_t}{\\partial W_{hh}} \\\\\\frac{\\partial \\mathcal{L}}{\\partial W_{hi}} = \\sum_{t=1}^T \\frac{\\partial \\mathcal{l}_t}{\\partial W_{hi}} =  \\sum_{t=1}^T \\frac{\\partial \\mathcal{l}_t}{\\partial o_t}\\frac{\\partial o_t}{\\partial h^o_t}W_{oh}\\frac{\\partial h_t}{\\partial h^i_t}\\frac{\\partial h^i_t}{\\partial W_{hi}}\\]<p>Note here you cannot directly calculate that $\\frac{\\partial h^i_t}{\\partial W_{hh}}=h_{t-1}$ since $h_{t-1} = h_{t-1}(\\cdot, W_{hh})$, that’s because $W_{hh}$ is shared across the whole sequence. Instead, we view the $h_t(W_{hh})$ as the composition of functions $h_t(h_{t-1}(W_{hh}), h_{t-2}(W_{hh}), … h_{1}(W_{hh}))$, applying the chain rule on the partial derivative, we have:</p>\\[\\frac{\\partial h_t}{\\partial W_{hh}}=\\sum_{k=1}^t \\frac{\\partial h_{t}}{\\partial h_{k}}\\frac{\\partial h_k}{W_{hh}}\\]",
            "url": "http://localhost:4000/2024/04/13/introllm",
            
            
            
            "tags": ["LLM","introduction","NLP"],
            
            "date_published": "2024-04-13T00:00:00+08:00",
            "date_modified": "2024-04-13T00:00:00+08:00",
            
                "author":  {
                "name": "Qihang Wang",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2024/04/10/fundmentalmath",
            "title": "Revisiting Mathematics in Deep Learning (or ML)",
            "summary": null,
            "content_text": "This post is the note for reviewing the fundamental mathematics in machine learning, especially, deep learning area. We will briefly revisit the basic concepts and useful tools in the analysis of ML algorithms.Here are some excellent materials you may find helpful:  Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning  The matrix cookbookIn fact, most of the contents in this post derive from [1].Table of Contents  Table of Contents          Preliminaries      Calculus                  Curves, Scalar Fields, and Gradients                    PreliminariesNote: This post assumes you have the preliminary knowledge of simple calculus in univariate case and linear algebra. Here provides some concepts which help us see the things in an abstract way (meaning that we then know where can or cannot we generalize our analysis to).(Derivative of the univariate scalar-valued function) A function is called differentiable at a point $a$ of its domain, if its domain contains an open interval containing $a$, and the limit:\\(\\lim_{h\\rightarrow 0}\\frac{f(a+h)-f(a)}{h}\\)exists. The $\\epsilon-\\delta$ definition of the derivative of $f(x)$ w.r.t its input $x$ states, $\\forall \\epsilon\\in\\mathbb{R}^+$,  $\\exist\\delta\\in\\mathbb{R}^+$, such that, $\\forall |h|&lt;\\delta$ and $f(a+h)$ is defined, and\\(|L-\\frac{f(a+h)-f(a)}{h}|&lt;\\epsilon\\)CalculusThis post assumes you have the preliminary knowledge of simple calculus in univariate case. The overall goal is to generalize the analysis on the function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ to $f:\\mathbb{R}^m\\rightarrow\\mathbb{R}^n$. Some useful concepts are:Curves, Scalar Fields, and GradientsThe curves take the form $f:\\mathbb{R}\\rightarrow\\mathbb{R}^n$. We could use $\\mathbf{x}(t)$ to denote the curve with $\\mathbf{x}\\in \\mathbf{R}^n$ and $t\\in\\mathbb{R}$. The curve is said to be differentiable if as $\\Delta t\\rightarrow 0$, we have $\\mathbf{x}(t+\\Delta t)-\\mathbf{x}(t)=\\mathbf{x}’(t)\\Delta t+\\mathcal{O}(\\Delta t^2)$. This serves as the definition of the derivative $\\mathbf{x}’(t)$:\\[\\frac{d\\mathbf{x}}{dt}=\\mathbf{x}'(t)=\\lim_{\\Delta t\\rightarrow 0}\\frac{\\Delta\\mathbf{x}}{\\Delta t}\\]it also follows that $\\frac{d}{dt}(\\mathbf{g}\\mathbf{h})=\\frac{d\\mathbf{g}}{dt}\\mathbf{h}+\\frac{d\\mathbf{h}}{dt}\\mathbf{g}$. The derivative is also called tangent vector sometimes. Note that the tangent vector depends on the selection of parameter $t$, which prevents us to obtain an invariant measure of the curve. We could instead study the arc length:\\(s=\\int_{t_0}^t dt'|x'(t')|\\)moreover, we have $\\Delta s=|\\Delta x|+\\mathcal{O}(|\\Delta x|^2)$ (as an aside, $|\\cdot|$ here means the length or norm of a vector), we then have $\\frac{ds}{dt}=sign(|x’|)$, where $sign(x)$ means that we need to set $x$ to be positive or negative according to whether the direction increase $t$ or not. With $s$ as our invariant parameterisation, we are able to define the induced tangent vector as $\\frac{dx}{ds}$, easy to verify that the norm of this tangent vector is always 1. Similarly, the ‘invariance’ induced by the arc-length could be applied into the curvature of the curve (the second order derivative) as $\\kappa(x)=\\frac{d^2 x}{ds^2}$. Now curves map a scalar parameter to a vector value $x\\in\\mathbb{R}^n$, the scalar field does the contrary: $\\phi:\\mathbb{R}^n\\rightarrow \\mathbb{R}$. Generally we can define the vector field as $\\phi:\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$. Consider the scalar field $\\phi$, we could access the derivatives by its gradient: \\(\\nabla \\phi=\\frac{\\partial\\phi}{\\partial x^i}\\mathbf{e}^i\\)Basicly we just take derivative of $\\phi$ w.r.t every coordinate, and constitute a new vector.",
            "content_html": "<p>This post is the note for reviewing the fundamental mathematics in machine learning, especially, deep learning area. We will briefly revisit the basic concepts and useful tools in the analysis of ML algorithms.</p><p>Here are some excellent materials you may find helpful:</p><ol>  <li><a href=\"https://www.cis.upenn.edu/~jean/math-deep.pdf\">Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning</a></li>  <li><a href=\"https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf\">The matrix cookbook</a></li></ol><p>In fact, most of the contents in this post derive from [1].</p><h1 id=\"table-of-contents\">Table of Contents</h1><ul>  <li><a href=\"#table-of-contents\">Table of Contents</a>    <ul>      <li><a href=\"#preliminaries\">Preliminaries</a></li>      <li><a href=\"#calculus\">Calculus</a>        <ul>          <li><a href=\"#curves-scalar-fields-and-gradients\">Curves, Scalar Fields, and Gradients</a></li>        </ul>      </li>    </ul>  </li></ul><h2 id=\"preliminaries\">Preliminaries</h2><p><strong>Note</strong>: This post assumes you have the preliminary knowledge of simple calculus in univariate case and linear algebra. Here provides some concepts which help us see the things in an abstract way (meaning that we then know where can or cannot we generalize our analysis to).</p><p>(Derivative of the univariate scalar-valued function) A function is called <em>differentiable</em> at a point $a$ of its domain, if its domain contains an open interval containing $a$, and the limit:\\(\\lim_{h\\rightarrow 0}\\frac{f(a+h)-f(a)}{h}\\)exists. The $\\epsilon-\\delta$ definition of the derivative of $f(x)$ w.r.t its input $x$ states, $\\forall \\epsilon\\in\\mathbb{R}^+$,  $\\exist\\delta\\in\\mathbb{R}^+$, such that, $\\forall |h|&lt;\\delta$ and $f(a+h)$ is defined, and\\(|L-\\frac{f(a+h)-f(a)}{h}|&lt;\\epsilon\\)</p><h2 id=\"calculus\">Calculus</h2><p>This post assumes you have the preliminary knowledge of simple calculus in univariate case. The overall goal is to generalize the analysis on the function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ to $f:\\mathbb{R}^m\\rightarrow\\mathbb{R}^n$. Some useful concepts are:</p><h3 id=\"curves-scalar-fields-and-gradients\">Curves, Scalar Fields, and Gradients</h3><p>The curves take the form $f:\\mathbb{R}\\rightarrow\\mathbb{R}^n$. We could use $\\mathbf{x}(t)$ to denote the curve with $\\mathbf{x}\\in \\mathbf{R}^n$ and $t\\in\\mathbb{R}$. The curve is said to be <em>differentiable</em> if as $\\Delta t\\rightarrow 0$, we have $\\mathbf{x}(t+\\Delta t)-\\mathbf{x}(t)=\\mathbf{x}’(t)\\Delta t+\\mathcal{O}(\\Delta t^2)$. This serves as the definition of the derivative $\\mathbf{x}’(t)$:</p>\\[\\frac{d\\mathbf{x}}{dt}=\\mathbf{x}'(t)=\\lim_{\\Delta t\\rightarrow 0}\\frac{\\Delta\\mathbf{x}}{\\Delta t}\\]<p>it also follows that $\\frac{d}{dt}(\\mathbf{g}\\mathbf{h})=\\frac{d\\mathbf{g}}{dt}\\mathbf{h}+\\frac{d\\mathbf{h}}{dt}\\mathbf{g}$. The derivative is also called <em>tangent vector</em> sometimes. Note that the tangent vector depends on the selection of parameter $t$, which prevents us to obtain an invariant measure of the curve. We could instead study the arc length:\\(s=\\int_{t_0}^t dt'|x'(t')|\\)moreover, we have $\\Delta s=|\\Delta x|+\\mathcal{O}(|\\Delta x|^2)$ (as an aside, $|\\cdot|$ here means the length or norm of a vector), we then have $\\frac{ds}{dt}=sign(|x’|)$, where $sign(x)$ means that we need to set $x$ to be positive or negative according to whether the direction increase $t$ or not. With $s$ as our invariant parameterisation, we are able to define the induced tangent vector as $\\frac{dx}{ds}$, easy to verify that the norm of this tangent vector is always 1. Similarly, the ‘invariance’ induced by the arc-length could be applied into the curvature of the curve (the second order derivative) as $\\kappa(x)=\\frac{d^2 x}{ds^2}$. Now curves map a scalar parameter to a vector value $x\\in\\mathbb{R}^n$, the scalar field does the contrary: $\\phi:\\mathbb{R}^n\\rightarrow \\mathbb{R}$. Generally we can define the vector field as $\\phi:\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$. Consider the scalar field $\\phi$, we could access the derivatives by its gradient: \\(\\nabla \\phi=\\frac{\\partial\\phi}{\\partial x^i}\\mathbf{e}^i\\)Basicly we just take derivative of $\\phi$ w.r.t every coordinate, and constitute a new vector.</p>",
            "url": "http://localhost:4000/2024/04/10/fundmentalmath",
            
            
            
            "tags": ["math","deep learning","algebra"],
            
            "date_published": "2024-04-10T00:00:00+08:00",
            "date_modified": "2024-04-10T00:00:00+08:00",
            
                "author":  {
                "name": "Qihang Wang",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2021/04/30/test-post-1",
            "title": "Building my blog",
            "summary": null,
            "content_text": "Despite there are a lot of ways to build a blog site, I utilized the jeckll academic theme and github pages to reduce the efforts. Find the commands and installation guides below:Installation$ git clone https://github.com/yak-fumblepack/jekyll-academic.git$ bundle installBuilding$ bundle exec jekyll buildUse --verbose if you would like a detailed log.Serving$ bundle exec jekyll serve --watch --livereload --incremental",
            "content_html": "<p>Despite there are a lot of ways to build a blog site, I utilized the jeckll academic theme and github pages to reduce the efforts. Find the commands and installation guides below:</p><h2 id=\"installation\">Installation</h2><pre><code class=\"language-shell\">$ git clone https://github.com/yak-fumblepack/jekyll-academic.git</code></pre><pre><code class=\"language-shell\">$ bundle install</code></pre><h2 id=\"building\">Building</h2><pre><code class=\"language-shell\">$ bundle exec jekyll build</code></pre><p>Use <code>--verbose</code> if you would like a detailed log.</p><h2 id=\"serving\">Serving</h2><pre><code class=\"language-shell\">$ bundle exec jekyll serve --watch --livereload --incremental</code></pre>",
            "url": "http://localhost:4000/2021/04/30/test-post-1",
            
            
            
            "tags": ["First post","Test"],
            
            "date_published": "2021-04-30T00:00:00+08:00",
            "date_modified": "2021-04-30T00:00:00+08:00",
            
                "author":  {
                "name": "Qihang Wang",
                "url": null,
                "avatar": null
                }
                
            
        }
    
    ]
}